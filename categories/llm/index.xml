<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on Snakinya-明烛天南</title>
    <link>https://www.snakin.top/categories/llm/</link>
    <description>Recent content in LLM on Snakinya-明烛天南</description>
    <generator>Hugo</generator>
    <language>cn</language>
    <lastBuildDate>Tue, 25 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.snakin.top/categories/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Llama3大模型本地部署指南</title>
      <link>https://www.snakin.top/posts/llama3%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97/</link>
      <pubDate>Tue, 25 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://www.snakin.top/posts/llama3%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97/</guid>
      <description>&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;&#xA;&lt;p&gt;项目地址：&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3&#34;&gt;https://github.com/ymcui/Chinese-LLaMA-Alpaca-3&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;该项目基于Meta最新发布的新一代开源大模型&lt;a href=&#34;https://github.com/facebookresearch/llama3&#34;&gt;Llama-3&lt;/a&gt;开发，是Chinese-LLaMA-Alpaca开源大模型相关系列项目（&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca&#34;&gt;一期&lt;/a&gt;、&lt;a href=&#34;https://github.com/ymcui/Chinese-LLaMA-Alpaca-2&#34;&gt;二期&lt;/a&gt;）的第三期。项目开源了&lt;strong&gt;中文Llama-3基座模型和中文Llama-3-Instruct指令精调大模型&lt;/strong&gt;。这些模型在原版Llama-3的基础上使用了大规模中文数据进行增量预训练，并且使用精选指令数据进行精调，进一步提升了中文基础语义和指令理解能力，相比二代相关模型获得了显著性能提升。&lt;/p&gt;&#xA;&lt;p&gt;这里我们需要下载的是GGUF格式的模型文件&lt;/p&gt;&#xA;&lt;p&gt;GGUF是一种二进制格式文件的规范，&lt;strong&gt;原始的大模型预训练结果经过转换后变成GGUF格式可以更快地被载入使用，也会消耗更低的资源&lt;/strong&gt;。原因在于GGUF采用了多种技术来保存大模型预训练结果，包括采用紧凑的二进制编码格式、优化的数据结构、内存映射等。因此采用相应的工具将原始模型预训练结果转换成GGUF之后可以更加高效的使用。&lt;/p&gt;&#xA;&lt;h2 id=&#34;环境配置&#34;&gt;环境配置&lt;/h2&gt;&#xA;&lt;h3 id=&#34;ollama&#34;&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Ollama是&lt;/strong&gt;一个轻量级且可扩展的框架，通过提供命令行界面，可以帮助用户在本地电脑上运行、创建和管理大语言模型（LLMs），整体感觉和Docker很像。&lt;/p&gt;&#xA;&lt;p&gt;项目地址：&lt;a href=&#34;https://ollama.com/download&#34;&gt;https://ollama.com/download&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;ollama-webui&#34;&gt;&lt;strong&gt;Ollama-webui&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;对应的前端界面，github下载安装即可&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/ollama-webui/ollama-webui-lite.git&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd ollama-webui-lite&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;npm install&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;npm run dev&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;启动之后如下&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://intranetproxy.alipay.com/skylark/lark/0/2024/png/142356518/1718767433040-6d3bd0df-4bef-4651-a35f-822cc5742487.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;模型部署&#34;&gt;模型部署&lt;/h2&gt;&#xA;&lt;p&gt;进入模型文件夹，创建Modelfile文件，用于配置ollama模型，定义了模型路径，聊天模板等信息。文件内容为&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;FROM ./ggml-model-q8_0.gguf&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TEMPLATE &amp;#34;&amp;#34;&amp;#34;{{ if .System }}&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{{ .System }}&amp;lt;|eot_id|&amp;gt;{{ end }}{{ if .Prompt }}&amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{{ .Prompt }}&amp;lt;|eot_id|&amp;gt;{{ end }}&amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{{ .Response }}&amp;lt;|eot_id|&amp;gt;&amp;#34;&amp;#34;&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;SYSTEM &amp;#34;&amp;#34;&amp;#34;You are a helpful assistant. 你是一个乐于助人的助手。&amp;#34;&amp;#34;&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;PARAMETER stop &amp;#34;&amp;lt;|start_header_id|&amp;gt;&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;PARAMETER stop &amp;#34;&amp;lt;|end_header_id|&amp;gt;&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;PARAMETER stop &amp;#34;&amp;lt;|eot_id|&amp;gt;&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;PARAMETER stop &amp;#34;&amp;lt;|reserved_special_token&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
  </channel>
</rss>
